{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you should implement a first version of a working machine learning model to predict the age of an Abalone.\n",
    "\n",
    "A few guidelines:\n",
    "- The model does not have to be complex. A simple linear regression model is enough.\n",
    "- You should use MLflow to track your experiments. You can use the MLflow UI to compare your experiments.\n",
    "- Do not push any MLflow data to the repository. Only the code to run the experiments is interesting and should be pushed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow import MlflowClient\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'file:///Users/nicolasschroeder/Programming/Abalone-Age-Prediction-XHEC-2024-25/notebooks/mlruns'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "experiments = client.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLS = [\"Sex\"]\n",
    "\n",
    "DATA_DIRPATH = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def filter_outliers(df: pd.DataFrame, min_rings: int = 1, max_rings: int = 20) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove rows corresponding to negative/zero\n",
    "    and too high target' values from the dataset\n",
    "    \"\"\"\n",
    "    return df[df[\"Rings\"].between(min_rings, max_rings)]\n",
    "\n",
    "\n",
    "def encode_categorical_cols(df: pd.DataFrame, categorical_cols: List[str] = None) -> pd.DataFrame:\n",
    "    \"\"\"Encode categorical columns as strings\"\"\"\n",
    "    if categorical_cols is None:\n",
    "        categorical_cols = CATEGORICAL_COLS\n",
    "    df.loc[:, categorical_cols] = df[categorical_cols].fillna(-1).astype(\"str\")\n",
    "    df.loc[:, categorical_cols] = df[categorical_cols].astype(\"str\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_x_y(\n",
    "    df: pd.DataFrame,\n",
    "    categorical_cols: List[str] = None,\n",
    "    dv: DictVectorizer = None,\n",
    "    with_target: bool = True,\n",
    ") -> Tuple[scipy.sparse.csr_matrix, np.ndarray, DictVectorizer]:\n",
    "    \"\"\"Extract X and y from the dataframe\"\"\"\n",
    "    if categorical_cols is None:\n",
    "        categorical_cols = CATEGORICAL_COLS\n",
    "    dicts = df[categorical_cols].to_dict(orient=\"records\")\n",
    "\n",
    "    y = None\n",
    "    if with_target:\n",
    "        if dv is None:\n",
    "            dv = DictVectorizer()\n",
    "            dv.fit(dicts)\n",
    "        y = df[\"Rings\"].values\n",
    "\n",
    "    x = dv.transform(dicts)\n",
    "    return x, y, dv\n",
    "\n",
    "\n",
    "def process_data(df: pd.DataFrame, dv=None, with_target: bool = True) -> scipy.sparse.csr_matrix:\n",
    "    \"\"\"\n",
    "    Load data from a parquet file\n",
    "    Compute target (duration column) and apply threshold filters (optional)\n",
    "    Turn features to sparse matrix\n",
    "    :return The sparce matrix, the target' values and the\n",
    "    dictvectorizer object if needed.\n",
    "    \"\"\"\n",
    "    if with_target:\n",
    "        df2 = filter_outliers(df)\n",
    "        logger.debug(f\"Encoding categorical columns...\")\n",
    "        df3 = encode_categorical_cols(df2)\n",
    "        logger.debug(f\"Extracting X and y...\")\n",
    "        return extract_x_y(df3, dv=dv)\n",
    "    else:\n",
    "        logger.debug(f\"Encoding categorical columns...\")\n",
    "        df2 = encode_categorical_cols(df)\n",
    "        logger.debug(f\"Extracting X and y...\")\n",
    "        return extract_x_y(df2, dv=dv, with_target=with_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_model(X: scipy.sparse.csr_matrix, y: np.ndarray) -> LinearRegression:\n",
    "    \"\"\"\n",
    "    Train a linear regression model on the given training data.\n",
    "    \n",
    "    Args:\n",
    "        X (scipy.sparse.csr_matrix): The feature matrix in sparse format.\n",
    "        y (np.ndarray): The target values corresponding to the features.\n",
    "    \n",
    "    Returns:\n",
    "        LinearRegression: The trained linear regression model.\n",
    "    \"\"\"\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X, y)\n",
    "    return lr\n",
    "\n",
    "\n",
    "def predict(X: scipy.sparse.csr_matrix, model: LinearRegression) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Use a trained linear regression model to make predictions on the given feature data.\n",
    "    \n",
    "    Args:\n",
    "        X (scipy.sparse.csr_matrix): The feature matrix in sparse format.\n",
    "        model (LinearRegression): The trained linear regression model.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: The predicted target values.\n",
    "    \"\"\"\n",
    "    return model.predict(X)\n",
    "\n",
    "\n",
    "def evaluate_model(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Evaluate the performance of the model by calculating the Root Mean Squared Error (RMSE).\n",
    "    \n",
    "    Args:\n",
    "        y_true (np.ndarray): The true target values.\n",
    "        y_pred (np.ndarray): The predicted target values from the model.\n",
    "    \n",
    "    Returns:\n",
    "        float: The calculated RMSE value, indicating the model's prediction error.\n",
    "    \"\"\"\n",
    "    return np.sqrt(root_mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "def train_model_workflow(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    ") -> Tuple[float, float, LinearRegression]:\n",
    "    \"\"\"\n",
    "    Complete workflow for training and evaluating a linear regression model.\n",
    "    \n",
    "    Args:\n",
    "        train_df (pd.DataFrame): The training dataset containing features and target values.\n",
    "        test_df (pd.DataFrame): The test dataset for evaluating the trained model.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[float, float, LinearRegression]: A tuple containing the RMSE for the training data,\n",
    "        RMSE for the test data, and the trained linear regression model.\n",
    "    \"\"\"\n",
    "    # Process the training data\n",
    "    x_train, y_train, dv = process_data(df=train_df)\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model = train_model(x_train, y_train)\n",
    "    \n",
    "    # Make predictions on the training data\n",
    "    y_pred_train = predict(x_train, model)\n",
    "    \n",
    "    # Calculate the RMSE for the training data\n",
    "    train_rmse = evaluate_model(y_train, y_pred_train)\n",
    "    \n",
    "    # Process the test data\n",
    "    x_test, y_test, _ = process_data(df=test_df, dv=dv)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred_test = predict(x_test, model)\n",
    "    \n",
    "    # Calculate the RMSE for the test data\n",
    "    test_rmse = evaluate_model(y_test, y_pred_test)\n",
    "    \n",
    "    return train_rmse, test_rmse, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/24 17:30:21 INFO mlflow.tracking.fluent: Experiment with name '/mlflow/abalone_linear_reg_test' does not exist. Creating a new experiment.\n",
      "\u001b[32m2024-10-24 17:30:21.136\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_data\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mEncoding categorical columns...\u001b[0m\n",
      "\u001b[32m2024-10-24 17:30:21.139\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_data\u001b[0m:\u001b[36m52\u001b[0m - \u001b[34m\u001b[1mExtracting X and y...\u001b[0m\n",
      "\u001b[32m2024-10-24 17:30:21.148\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_data\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mEncoding categorical columns...\u001b[0m\n",
      "\u001b[32m2024-10-24 17:30:21.149\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_data\u001b[0m:\u001b[36m52\u001b[0m - \u001b[34m\u001b[1mExtracting X and y...\u001b[0m\n",
      "2024/10/24 17:30:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'linear_reg_test' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'linear_reg_test'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Set the experiment name for tracking\n",
    "mlflow_experiment_path = \"/mlflow/abalone_linear_reg_test\"\n",
    "mlflow.set_experiment(mlflow_experiment_path)\n",
    "\n",
    "# Start an MLflow run for tracking the experiment\n",
    "with mlflow.start_run() as run:\n",
    "    # Get the run ID for future reference\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    # Set metadata tags for this run\n",
    "    mlflow.set_tag(\"Level\", \"Development\")\n",
    "    mlflow.set_tag(\"Team\", \"Data Science\")\n",
    "    \n",
    "    # Load dataset from CSV\n",
    "    df = pd.read_csv(f\"{DATA_DIRPATH}/abalone.csv\")\n",
    "    \n",
    "    # Split the dataset into training and test sets (70% training, 30% test)\n",
    "    train_df, test_df = train_test_split(df, test_size=0.30, random_state=42)\n",
    "\n",
    "    # Train the model and get RMSE for both train and test sets\n",
    "    train_rmse, test_rmse, model = train_model_workflow(\n",
    "        train_df=train_df,\n",
    "        test_df=test_df,\n",
    "    )\n",
    "\n",
    "    # Log the dataset sizes (number of rows in train and test sets) as parameters\n",
    "    mlflow.log_param(\"train_set_size\", train_df.shape[0])\n",
    "    mlflow.log_param(\"test_set_size\", test_df.shape[0])\n",
    "\n",
    "    # Log whether any data preprocessing such as filtering outliers was performed\n",
    "    mlflow.log_param(\"filtered_outliers\", True)\n",
    "\n",
    "    # Log RMSE metrics for training and test sets\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    # Log the trained model to MLflow\n",
    "    mlflow.sklearn.log_model(model, \"models\")\n",
    "\n",
    "    # Register the model in the MLflow model registry for future production use\n",
    "    mlflow.register_model(f\"runs:/{run_id}/models\", \"linear_reg_test\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
