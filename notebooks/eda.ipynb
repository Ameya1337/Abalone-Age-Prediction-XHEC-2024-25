{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA (Exploratory Data Analysis) of the dataset\n",
    "\n",
    "In this notebook, explore the Abalone dataset, by showing relevant visualizations that help understand the problem you are modelling.\n",
    "\n",
    "Please make sure to write down your conclusions in the final notebook and to remove these intructions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "from sklearn.model_selection import  train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import  RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import  GradientBoostingRegressor\n",
    "from sklearn.linear_model import  Ridge\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/abalone.csv\")\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From problem statement and feature discription, let's first compute the target variable of the problem ' Age' and assign it to the dataset. Age = 1.5+Ring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age'] = data['Rings']+1.5\n",
    "data.drop('Rings', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This dataset has {} observations with {} features.'.format(data.shape[0], data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key insights: <br> <br>\n",
    "No missing values in the dataset <br>\n",
    "All numerical features but 'sex'<br>\n",
    "Though features are not normaly distributed, are close to normality <br>\n",
    "None of the features have minimum = 0 except Height <br>\n",
    "Each feature has difference scale range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(figsize=(20,10), grid=False, layout=(2, 4), bins = 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = data.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = data.select_dtypes(include=[object]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_values = skew(data[numerical_features], nan_policy = 'omit')\n",
    "dummy = pd.concat([pd.DataFrame(list(numerical_features), columns=['Features']), \n",
    "        pd.DataFrame(list(skew_values), columns=['Skewness degree'])], axis = 1)\n",
    "dummy.sort_values(by = 'Skewness degree' , ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For normally distributed data, the skewness should be about 0. For unimodal continuous distributions, a skewness value > 0 means that there is more weight in the right tail of the distribution. The function skewtest can be used to determine if the skewness value is close enough to 0, statistically speaking. <br>\n",
    "Height has highest skewedness followed by age, Shucked weight (can be cross verified through histogram plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = 'Sex', data = data, palette=\"Set3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Sex')[['Length', 'Diameter', 'Height', 'Whole weight', 'Shucked weight','Viscera weight', 'Shell weight', 'age']].mean().sort_values('age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Analysis\n",
    "Bivariate analysis is a vital part of data analysis process, for it gives clear picture on how each features are affected in presence of other features.\n",
    "It also helps understand and identify significance features, overcome multi-collinearity effect, and inter-dependency. Thus, it provides insights on hidden data noise pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data[numerical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key insights: <br> <br>\n",
    "length is linearly correlated with diameter and non-linearly correlated with height, whole weight, shucked weight, viscera weight, and shell weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "sns.heatmap(data[numerical_features].corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whole Weight is almost linearly correlated with all other features except age <br>\n",
    "Height has least linearity with remaining features <br>\n",
    "Age is most linearly proprtional with Shell Weight, followed by Diameter and length <br>\n",
    "Age is least correlated with Shucked Weight <br>\n",
    "Such high correlation coefficients among features can result into multi-collinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data.drop(columns=['age']))\n",
    "dummy_data = data.copy()\n",
    "data.boxplot( rot = 90, figsize=(20,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Numerical Features (Length, Diameter, Height, Weights): Most of the numerical features, such as Length, Diameter, and the different weight measures (Whole weight, Shucked weight, Viscera weight, Shell weight), exhibit some degree of outliers. These outliers are visible as individual points that extend beyond the whiskers of the boxplot. Notably, the feature Whole weight has a particularly wide range and a significant number of outliers, indicating variability in this measure.\n",
    "\n",
    "- Height: The Height feature appears to have a concentration of outliers below the lower whisker, suggesting there are many samples with unusually small heights. This might warrant further investigation to determine if these values are accurate or the result of data entry errors.\n",
    "\n",
    "- Categorical Features (Sex_F, Sex_I, Sex_M): The categorical features (sex columns) appear as flat boxplots because they are encoded as binary variables, hence they don’t exhibit typical boxplot variability. These features don’t provide insight through boxplots, but can be explored through other statistical or visualization techniques.\n",
    "\n",
    "General Observation: Most of the weight-related features have considerable variability with multiple outliers, which suggests that outlier treatment (like removal or transformation) might be necessary before applying machine learning models. Features such as Length and Diameter are relatively more stable, though they still show some outliers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
